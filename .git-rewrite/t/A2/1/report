1
a. 	Test Data Accuracy: 	0.6081455002318311
   	Train Data Accuracy:	0.6570656156987092

b.	random prediction accuracy:		0.19929254101915972
	majority prediction accuracy:	0.439895900327555

c.
	Confusion matrix:
	[[14777  3233  1164   587   408]
	 [ 2965  2841  3213  1397   422]
	 [ 1395  1397  4584  6169   986]
	 [ 1084   527  1918 18481  7348]
	 [ 2898   233   409 14645 40637]]

d.

words = [word for word in tokens if word.isalpha()]

on train.json(with stemming): 
	accuracy: 0.6001809778788196
	confusion matrix:
	 [[14663  3243  1114   626   523]
	 [ 3104  2747  2966  1479   542]
	 [ 1551  1310  4464  5958  1248]
	 [ 1216   481  1953 17807  7901]
	 [ 3130   242   485 14391 40574]]
	F1_score: [0.669039 0.291289 0.349939 0.511556 0.740334]
	macro_f1_score: 0.5124314245134586
	Time taken: 1606.2611441612244

e.

only bi-grams:
		accuracy: 0.6336394501862128
		confusion matrix:
		 [[16512  1047   808  1158   644]
		 [ 4035  1063  1958  3085   697]
		 [ 1660   331  2308  8588  1644]
		 [  772   113   674 16894 10905]
		 [ 1304   114   271  9181 47952]]
		F1_score: [0.742914 0.157412 0.224623 0.494961 0.794802]
		macro_f1_score: 0.4829421864499718
		Time taken: 1419.654305934906

bi-grams along with single words:	

1st		accuracy: 0.6297955398674823
		confusion matrix:
		 [[15957  1862  1044   870   436]
		 [ 3668  1805  2563  2337   465]
		 [ 1692   559  3146  7955  1179]
		 [  996   130   901 18557  8774]
		 [ 1881    87   241 11863 44750]]
		F1_score: [0.719383 0.236241 0.280567 0.523175 0.782165]
		macro_f1_score: 0.5083061917191372
		Time taken: 1696.7981586456299

2nd		accuracy: 0.6337665834068712
		confusion matrix:
		 [[16087  1826   988   866   402]
		 [ 3699  1748  2597  2337   457]
		 [ 1672   549  3112  8035  1163]
		 [  951   130   858 18636  8783]
		 [ 1773    80   238 11568 45163]]
		F1_score: [0.72544  0.23044  0.278803 0.526441 0.78688 ]
		macro_f1_score: 0.5096008085667505
		Time taken: 1607.8817052841187

		
f. done

g.

without bi-grams:
		accuracy: 0.6159679325146951
		confusion matrix:
		 [[14439  3719  1119   434   458]
		 [ 2834  3483  3038  1042   441]
		 [ 1450  1459  5722  4821  1079]
		 [ 1204   658  2137 18124  7235]
		 [ 3129   310   509 14276 40598]]
		F1_score: [0.668086 0.340353 0.422975 0.532628 0.747434]
		macro_f1_score: 0.5422949950557527
		Time taken: 10690.201118707657

bi-grams(on top of single words):
		accuracy: 0.731517073243692
		confusion matrix:
		 [[16457  2080  1011   425   196]
		 [ 2724  4680  2060  1137   237]
		 [ 1358   453  7646  4379   695]
		 [  887   137   503 22066  5765]
		 [ 1456    56   163 10179 46968]]
		F1_score: [0.764535 0.513045 0.590106 0.653381 0.833631]
		macro_f1_score: 0.6709396664817443
		Time taken: 7981.045243263245
		
		